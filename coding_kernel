{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:23:16.317856Z",
     "start_time": "2020-04-27T05:23:15.935893Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:23:16.325572Z",
     "start_time": "2020-04-27T05:23:16.320293Z"
    }
   },
   "outputs": [],
   "source": [
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:23:16.342183Z",
     "start_time": "2020-04-27T05:23:16.336480Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'Trail-Race 4.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:23:17.026224Z",
     "start_time": "2020-04-27T05:23:16.424780Z"
    }
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open('./app/model_rf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:23:20.988594Z",
     "start_time": "2020-04-27T05:23:20.422097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: ./data/M2020-04-26D.xls\n",
      "Loaded: Race(1)\n",
      "Loaded: Race(2)\n",
      "Loaded: Race(3)\n",
      "Loaded: Race(4)\n",
      "Loaded: Race(5)\n",
      "Loaded: Race(6)\n",
      "Loaded: Race(7)\n",
      "Loaded: Race(8)\n",
      "Loaded: Race(9)\n",
      "Loaded: Race(10)\n",
      "Status: Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_whole_excel('./data/M2020-04-26D.xls', 'Race', combined=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:56:37.510986Z",
     "start_time": "2020-04-27T05:56:37.339490Z"
    }
   },
   "outputs": [],
   "source": [
    "base_col = ['東(正)','東(副)','東(冷)','蘋(正)','蘋(副)','蘋(冷)','專(正)','專(副)','專(冷)']\n",
    "odd_col = [i for i in list(data) if re.findall(r'[\\w|\\s|.]+FixOdd$', i)]\n",
    "main_col = base_col + odd_col\n",
    "\n",
    "supportive_col = ['horse_num','sheet_name']\n",
    "\n",
    "# column index with nan\n",
    "odd_zero_idx = list(data[(data[odd_col] == 0).sum(1) >= 1].index)\n",
    "problematic_idx = list(data[main_col][data[main_col].isna().sum(1) >= 1].index) + odd_zero_idx\n",
    "\n",
    "# dataframe of two parts\n",
    "main_df = data[main_col].drop(problematic_idx)\n",
    "supportive_df = data[supportive_col].drop(problematic_idx)\n",
    "\n",
    "# predict result\n",
    "predict_result = model.predict_proba(main_df)[:,1]\n",
    "\n",
    "supportive_df['Probability'] = predict_result\n",
    "\n",
    "# append dropped problematic df\n",
    "append_df = data.loc[problematic_idx][supportive_col]\n",
    "append_df['Probability'] = ['Nan']*append_df.shape[0]\n",
    "\n",
    "final_df = pd.concat([supportive_df, append_df])\n",
    "\n",
    "# subset df base on race number\n",
    "subset = subset_df(final_df, 'sheet_name')\n",
    "\n",
    "# padded to 14\n",
    "padded = [pad_df(i, 'Probability', 14) for i in subset]\n",
    "\n",
    "padded_renamed = list()\n",
    "for i in subset:\n",
    "    df = pad_df(i, 'Probability', 14)\n",
    "    df = rename_column_drop_one(df, 'sheet_name')\n",
    "    padded_renamed.append(df)\n",
    "    \n",
    "cleaned_df = pd.concat(padded_renamed, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T05:57:15.969487Z",
     "start_time": "2020-04-27T05:57:15.960721Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in list(cleaned_df):\n",
    "    if 'Probability' in i:\n",
    "        all_cleaned = [to_str_percent(i, 2) for i in cleaned_df[i]]\n",
    "        cleaned_df[i] = all_cleaned\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_digit = [i for i in list(cleaned_df) if re.findall(r'[\\w|_|]+\\([0-9]{2}\\)$', i)]\n",
    "single_digit = [i for i in list(cleaned_df) if i not in double_digit]\n",
    "\n",
    "out_df = pd.concat([cleaned_df[single_digit], cleaned_df[double_digit]], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
